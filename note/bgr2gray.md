优化结果：

| 实现/耗时(ms)     | 320x240    | 1280x720   | 1920x1080 | 3840x2160 |
| ----------------- | ---------- | ---------- | --------- | --------- |
| naive             | 0.050      | 0.577      | 1.299     | 5.387     |
| opencv实现        | 0.016      | 0.156      | 0.356     | 1.424     |
| **neon加速**      | 0.007      | 0.0727     | 0.166     | 0.683     |
| **更快的neon_v2** | **0.0052** | **0.0537** | **0.124** | **0.519** |



## bgr2gray实现

代码：`cv/arm/bgr2gray.cpp`

| 实现/耗时(ms) | 320x240 | 1280x720 | 1920x1080 | 3840x2160 |
| ------------- | ------- | -------- | --------- | --------- |
| naive         | 0.050   | 0.577    | 1.299     | 5.387     |
| opencv        | 0.016   | 0.156    | 0.356     | 1.424     |
| **neon加速**  | 0.007   | 0.0727   | 0.166     | 0.683     |

opencv的[BGR2Gray实现](https://github.com/opencv/opencv/blob/master/modules/imgproc/src/color_rgb.simd.hpp#L666) 比我的实现要慢1倍多，原因有两点：

1. 我使用u8代替浮点计算，opencv采用s16(short)代替浮点计算。数据吞吐量是我的1/2。这是主要原因。

2. opencv做了round操作，即 `short gray = r * RY15 + g * GY15 + B * BY15 + 2^14   `  ，相当于  

   ```c++
   float ff = 1.4f;
   int i = int(ff + 0.5f);
   ```

   这也使得计算量变多了。



### 还能更快吗？

观察neon实现在读取、写入内存时的代码：

```c++
//读取bgr
uint8x8x3_t v_bgr = vld3_u8(src);
...
//写入gray
vst1_u8(dst, v_gray);
```

都是在以 64-bit 宽度进行内存交换，并没有使用128-bit宽度的 `vld3q_u8` 和 `vst1q_u8` intrinsics。如果使用 `vld3q_u8` 和 `vst1q_u8` ，可以将访存次数减少 1/2。

使用该思路优化，可以进一步提升25%左右的速度，效果相当明显的。

| 实现/耗时(ms)     | 320x240 | 1280x720 | 1920x1080 | 3840x2160 |
| ----------------- | ------- | -------- | --------- | --------- |
| **更快的neon_v2** | 0.0052  | 0.0537   | 0.124     | 0.519     |









## 注意事项

1. 参数需要转整型：RGB 2 GRAY的计算公式是 

   ![img](https://pic3.zhimg.com/80/v2-ac351cfe72ac84b62639a0bfce55334e_1440w.webp)

   但是像素值是u8类型，无法和f32类型的参数做运算，所以要将参数定点化，而且要定点化为u8，这样才能运算

2. 无法做u8的向量 - 标量 乘法

   检索neon intrinsic，发现没有 vmull_n_u8 指令。

   只能将标量dup之后，做向量 - 向量乘法